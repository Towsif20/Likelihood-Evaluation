{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_file = \"E:\\\\Studies\\\\4-1\\CSE 400\\\\codes\\sam_files\\\\canu_05.sam\"\n",
    "read_file = \"E:\\\\Studies\\\\4-1\\\\CSE 400\\\\drive\\\\inputs\\\\real_SAMN10819805_pacbio_00.fastq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open(sam_file,'r')\n",
    "line=file.readline()\n",
    "line=line.strip()\n",
    "line=line.strip('\\n')\n",
    "array=[]\n",
    "allLineFromaln=[]\n",
    "lineCountInMapFile=0\n",
    "while line:\n",
    "    if(line[0]=='@'):\n",
    "        line=file.readline()\n",
    "        line=line.strip()\n",
    "        line=line.strip('\\n')\n",
    "        continue\n",
    "    line=re.split('\\t',line)\n",
    "    lineCountInMapFile+=1\n",
    "    temp=[]\n",
    "    for j in range(12):\n",
    "        temp.append(line[j])\n",
    "    allLineFromaln.append(temp)\n",
    "    line=file.readline()\n",
    "    line=line.strip()\n",
    "    line=line.strip('\\n')\n",
    "\n",
    "allLine=np.array(allLineFromaln,dtype='object')\n",
    "# print(allLine.shape)\n",
    "readTemplateAln=allLine[:,0]\n",
    "flag=allLine[:,1]\n",
    "RnameAln=allLine[:,2]\n",
    "pos=allLine[:,3]\n",
    "cigar=allLine[:,5]\n",
    "seq=allLine[:,9]\n",
    "qual=allLine[:,10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hash Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashTable:\n",
    "\n",
    "\t# Create empty bucket list of given size\n",
    "\tdef __init__(self, size):\n",
    "\t\tself.size = size\n",
    "\t\tself.hash_table = self.create_buckets()\n",
    "\n",
    "\tdef create_buckets(self):\n",
    "\t\treturn [[] for _ in range(self.size)]\n",
    "\n",
    "\t# Insert values into hash map\n",
    "\tdef set_val(self, key, val):\n",
    "\t\t\n",
    "\t\t# Get the index from the key\n",
    "\t\t# using hash function\n",
    "\t\thashed_key = hash(key) % self.size\n",
    "\t\t\n",
    "\t\t# Get the bucket corresponding to index\n",
    "\t\tbucket = self.hash_table[hashed_key]\n",
    "\n",
    "\t\tfound_key = False\n",
    "\t\tfor index, record in enumerate(bucket):\n",
    "\t\t\trecord_key, record_val = record\n",
    "\t\t\t\n",
    "\t\t\t# check if the bucket has same key as\n",
    "\t\t\t# the key to be inserted\n",
    "\t\t\tif record_key == key:\n",
    "\t\t\t\tfound_key = True\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\t# If the bucket has same key as the key to be inserted,\n",
    "\t\t# Update the key value\n",
    "\t\t# Otherwise append the new key-value pair to the bucket\n",
    "\t\tif found_key:\n",
    "\t\t\tbucket[index] = (key, val)\n",
    "\t\telse:\n",
    "\t\t\tbucket.append((key, val))\n",
    "\n",
    "\t# Return searched value with specific key\n",
    "\tdef get_val(self, key):\n",
    "\t\t\n",
    "\t\t# Get the index from the key using\n",
    "\t\t# hash function\n",
    "\t\thashed_key = hash(key) % self.size\n",
    "\t\t\n",
    "\t\t# Get the bucket corresponding to index\n",
    "\t\tbucket = self.hash_table[hashed_key]\n",
    "\n",
    "\t\tfound_key = False\n",
    "\t\tfor index, record in enumerate(bucket):\n",
    "\t\t\trecord_key, record_val = record\n",
    "\t\t\t\n",
    "\t\t\t# check if the bucket has same key as\n",
    "\t\t\t# the key being searched\n",
    "\t\t\tif record_key == key:\n",
    "\t\t\t\tfound_key = True\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\t# If the bucket has same key as the key being searched,\n",
    "\t\t# Return the value found\n",
    "\t\t# Otherwise indicate there was no record found\n",
    "\t\tif found_key:\n",
    "\t\t\treturn record_val\n",
    "\t\telse:\n",
    "\t\t\treturn \"No record found\"\n",
    "\n",
    "\t# Remove a value with specific key\n",
    "\tdef delete_val(self, key):\n",
    "\t\t\n",
    "\t\t# Get the index from the key using\n",
    "\t\t# hash function\n",
    "\t\thashed_key = hash(key) % self.size\n",
    "\t\t\n",
    "\t\t# Get the bucket corresponding to index\n",
    "\t\tbucket = self.hash_table[hashed_key]\n",
    "\n",
    "\t\tfound_key = False\n",
    "\t\tfor index, record in enumerate(bucket):\n",
    "\t\t\trecord_key, record_val = record\n",
    "\t\t\t\n",
    "\t\t\t# check if the bucket has same key as\n",
    "\t\t\t# the key to be deleted\n",
    "\t\t\tif record_key == key:\n",
    "\t\t\t\tfound_key = True\n",
    "\t\t\t\tbreak\n",
    "\t\tif found_key:\n",
    "\t\t\tbucket.pop(index)\n",
    "\t\treturn\n",
    "\n",
    "\t# To print the items of hash map\n",
    "\tdef __str__(self):\n",
    "\t\treturn \"\".join(str(item) for item in self.hash_table)\n",
    "\n",
    "\n",
    "# hash_table = HashTable(50)\n",
    "\n",
    "# # insert some values\n",
    "# hash_table.set_val('gfg@example.com', 'some value')\n",
    "# print(hash_table)\n",
    "# print()\n",
    "\n",
    "# hash_table.set_val('portal@example.com', 'some other value')\n",
    "# print(hash_table)\n",
    "# print()\n",
    "\n",
    "# # search/access a record with key\n",
    "# print(hash_table.get_val('portal@example.com'))\n",
    "# print()\n",
    "\n",
    "# # delete or remove a value\n",
    "# hash_table.delete_val('portal@example.com')\n",
    "# print(hash_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Raw Read and Raw Template from pacbio Read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open(read_file,'r')\n",
    "line=file.readline()\n",
    "line=line.strip()\n",
    "line=line.strip('\\n')\n",
    "readCountRaw=0\n",
    "readTemplateraw=[]\n",
    "readNameraw=[]\n",
    "readLengthsRaw=[]\n",
    "while line:\n",
    "    if line[0]=='@':\n",
    "        line=re.split(\"@| |\\t\",line)\n",
    "        line=line[1]\n",
    "        readTemplateraw.append(line)\n",
    "        read=file.readline().strip()\n",
    "        read=read.strip('\\n')\n",
    "        readNameraw.append(read)\n",
    "        readLengthsRaw.append(len(readNameraw[len(readNameraw)-1]))\n",
    "        readCountRaw +=1\n",
    "    line=file.readline()\n",
    "file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_table=HashTable(readCountRaw)\n",
    "for i in range(readCountRaw):\n",
    "    hash_table.set_val(readTemplateraw[i],readNameraw[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate mapped and unmapped file from aligned sam file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# *********************************************************\n",
    "# read_template_name  flag    mapping_postion ciger   read_seq--->mapped file sequence\n",
    "#@read_template_name\\n read\\n +read_template_name\\n qual\\n ---> unmapped file sequence\n",
    "\n",
    "# ************************************************************\n",
    "mappedFile=open('mappedread.txt','w')\n",
    "unmappedFile=open('unmapped.txt','w')\n",
    "modifiedRandomUnmapped=open('modifiedRandomSliceUnmapped.txt','w')\n",
    "unmappedLengths=[]\n",
    "for i in range(lineCountInMapFile):\n",
    "    line=readTemplateAln[i]+'\\t'+flag[i]+'\\t'+RnameAln[i]+'\\t'+pos[i]+'\\t'+cigar[i]+'\\t'+hash_table.get_val(readTemplateAln[i])+'\\t'+qual[i]\n",
    "    if pos[i]=='0':\n",
    "        unmappedFile.write(\"@\"+readTemplateAln[i]+\"\\n\")\n",
    "        unmappedFile.write(hash_table.get_val(readTemplateAln[i])+\"\\n\")\n",
    "        unmappedFile.write(\"+\"+\"\\n\")\n",
    "        unmappedFile.write(qual[i]+\"\\n\")\n",
    "        unmappedLengths.append(len(hash_table.get_val(readTemplateAln[i])))\n",
    "\n",
    "        readSequence=hash_table.get_val(readTemplateAln[i])\n",
    "        qualSequence=qual[i]\n",
    "        if len(readSequence) > 1000:\n",
    "            space=len(readSequence)-1000\n",
    "            randomSlice=random.randint(0,space)\n",
    "            readSequence=readSequence[randomSlice:randomSlice+1000]\n",
    "            qualSequence=qualSequence[randomSlice:randomSlice+1000]\n",
    "\n",
    "        modifiedRandomUnmapped.write(\"@\"+readTemplateAln[i]+\"\\n\")\n",
    "        modifiedRandomUnmapped.write(readSequence+\"\\n\")\n",
    "        modifiedRandomUnmapped.write(\"+\"+\"\\n\")\n",
    "        modifiedRandomUnmapped.write(qualSequence+\"\\n\")\n",
    "\n",
    "    else:\n",
    "        mappedFile.write('%s\\n' % line)\n",
    "\n",
    "\n",
    "mappedFile.close()\n",
    "unmappedFile.close()\n",
    "modifiedRandomUnmapped.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min  35  max  36604\n",
      "total unmapped  2480\n",
      "737\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#get minimum value from unmappedLengths\n",
    "min_value=min(unmappedLengths)\n",
    "#get maximum value from unmappedLengths\n",
    "max_value=max(unmappedLengths)\n",
    "print(\"min \",min_value , \" max \",max_value)\n",
    "print(\"total unmapped \",len(unmappedLengths))\n",
    "#position of min value\n",
    "min_index=unmappedLengths.index(min_value)\n",
    "print(min_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save unmapped statistics in file\n",
    "file=open('unmapped_statistics.txt','w')\n",
    "file.write(\"TotalLength\\t\"+str(sum(unmappedLengths))+\"\\n\")\n",
    "file.write(\"Total unmapped Read Count : \"+\"%s\" %len(unmappedLengths)+\"\\n\")\n",
    "file.write(\"min read Lendth \"+\"%s\" % min_value+\"\\n\")\n",
    "file.write(\"max read Lendth \"+\"%s\" %max_value+\"\\n\")\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "statFile=open('OverallStatistics.txt','w')\n",
    "totalReadCount=readCountRaw\n",
    "unmappedReadCount=(pos=='0').sum()\n",
    "mappedReadCount=totalReadCount-unmappedReadCount\n",
    "totalReadCount=\"%s\" % totalReadCount\n",
    "unmappedReadCount=\"%s\" % unmappedReadCount\n",
    "mappedReadCount=\"%s\" % mappedReadCount\n",
    "line=\"Total Read : \"+totalReadCount+\"\\t\"+\"Mapped Read Count : \"+mappedReadCount+\"\\t\"+\"Unmapped Read Count : \"+unmappedReadCount\n",
    "statFile.write('%s' %line)\n",
    "statFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unmapped statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statFile=open('stat.txt','w')\n",
    "totalReadCount=readCountRaw\n",
    "unmappedReadCount=(pos=='0').sum()\n",
    "mappedReadCount=totalReadCount-unmappedReadCount\n",
    "totalReadCount=\"%s\" % totalReadCount\n",
    "unmappedReadCount=\"%s\" % unmappedReadCount\n",
    "line=totalReadCount+\"\\t\"+unmappedReadCount+\"\\t\"+\"%s\" %max_value\n",
    "statFile.write('%s' %line)\n",
    "statFile.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f027b4592910bbddabc03320229ffb3bed0d0840b4364d0114aa85295a38f7d3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
