{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "class HashTable:\n",
    "\n",
    "\t# Create empty bucket list of given size\n",
    "\tdef __init__(self, size):\n",
    "\t\tself.size = size\n",
    "\t\tself.hash_table = self.create_buckets()\n",
    "\n",
    "\tdef create_buckets(self):\n",
    "\t\treturn [[] for _ in range(self.size)]\n",
    "\n",
    "\t# Insert values into hash map\n",
    "\tdef set_val(self, key, val):\n",
    "\t\t\n",
    "\t\t# Get the index from the key\n",
    "\t\t# using hash function\n",
    "\t\thashed_key = hash(key) % self.size\n",
    "\t\t\n",
    "\t\t# Get the bucket corresponding to index\n",
    "\t\tbucket = self.hash_table[hashed_key]\n",
    "\n",
    "\t\tfound_key = False\n",
    "\t\tfor index, record in enumerate(bucket):\n",
    "\t\t\trecord_key, record_val = record\n",
    "\t\t\t\n",
    "\t\t\t# check if the bucket has same key as\n",
    "\t\t\t# the key to be inserted\n",
    "\t\t\tif record_key == key:\n",
    "\t\t\t\tfound_key = True\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\t# If the bucket has same key as the key to be inserted,\n",
    "\t\t# Update the key value\n",
    "\t\t# Otherwise append the new key-value pair to the bucket\n",
    "\t\tif found_key:\n",
    "\t\t\tbucket[index] = (key, val)\n",
    "\t\telse:\n",
    "\t\t\tbucket.append((key, val))\n",
    "\n",
    "\t# Return searched value with specific key\n",
    "\tdef get_val(self, key):\n",
    "\t\t\n",
    "\t\t# Get the index from the key using\n",
    "\t\t# hash function\n",
    "\t\thashed_key = hash(key) % self.size\n",
    "\t\t\n",
    "\t\t# Get the bucket corresponding to index\n",
    "\t\tbucket = self.hash_table[hashed_key]\n",
    "\n",
    "\t\tfound_key = False\n",
    "\t\tfor index, record in enumerate(bucket):\n",
    "\t\t\trecord_key, record_val = record\n",
    "\t\t\t\n",
    "\t\t\t# check if the bucket has same key as\n",
    "\t\t\t# the key being searched\n",
    "\t\t\tif record_key == key:\n",
    "\t\t\t\tfound_key = True\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\t# If the bucket has same key as the key being searched,\n",
    "\t\t# Return the value found\n",
    "\t\t# Otherwise indicate there was no record found\n",
    "\t\tif found_key:\n",
    "\t\t\treturn record_val\n",
    "\t\telse:\n",
    "\t\t\treturn \"No\"\n",
    "\n",
    "\t# Remove a value with specific key\n",
    "\tdef delete_val(self, key):\n",
    "\t\t\n",
    "\t\t# Get the index from the key using\n",
    "\t\t# hash function\n",
    "\t\thashed_key = hash(key) % self.size\n",
    "\t\t\n",
    "\t\t# Get the bucket corresponding to index\n",
    "\t\tbucket = self.hash_table[hashed_key]\n",
    "\n",
    "\t\tfound_key = False\n",
    "\t\tfor index, record in enumerate(bucket):\n",
    "\t\t\trecord_key, record_val = record\n",
    "\t\t\t\n",
    "\t\t\t# check if the bucket has same key as\n",
    "\t\t\t# the key to be deleted\n",
    "\t\t\tif record_key == key:\n",
    "\t\t\t\tfound_key = True\n",
    "\t\t\t\tbreak\n",
    "\t\tif found_key:\n",
    "\t\t\tbucket.pop(index)\n",
    "\t\treturn\n",
    "\n",
    "\t# To print the items of hash map\n",
    "\tdef __str__(self):\n",
    "\t\treturn \"\".join(str(item) for item in self.hash_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ilen: 34190402.0\n",
      "Icount: 20681987.0\n",
      "Dlen: 152584408.0\n",
      "Dcount: 13434376.0\n",
      "Mlen: 360274608.0\n"
     ]
    }
   ],
   "source": [
    "#read list from file baseMatrix.txt\n",
    "#calculate probability for each element in the list\n",
    "file=open(\"baseMatrix.txt\",\"r\")\n",
    "line=file.readline()\n",
    "baseMatrix=[]\n",
    "while(line):\n",
    "    line=line.strip()\n",
    "    line=line.split()\n",
    "    baseMatrix.append(line)\n",
    "    line=file.readline()\n",
    "file.close()\n",
    "#convert baseMatrix to float\n",
    "baseMatrix=[[float(i) for i in j] for j in baseMatrix]\n",
    "#make baseMatrix a numpy array\n",
    "baseMatrix=np.array(baseMatrix)\n",
    "# print(baseMatrix)\n",
    "\n",
    "# get Insertion counts\n",
    "file=open(\"insertion.txt\",\"r\")\n",
    "line=file.readline()\n",
    "line=line.split()\n",
    "Ilen=float(line[0])\n",
    "Icount=float(line[1])\n",
    "line=file.readline()\n",
    "insertionCount=line\n",
    "insertionCount=insertionCount.split()\n",
    "insertionCount=list(map(float,insertionCount))\n",
    "insertionCount=np.array(insertionCount)\n",
    "file.close()\n",
    "\n",
    "# get deletion counts\n",
    "file=open(\"deletion.txt\",\"r\")\n",
    "line=file.readline()\n",
    "line=line.split()\n",
    "Dlen=float(line[0])\n",
    "Dcount=float(line[1])\n",
    "line=file.readline()\n",
    "deletionCount=line\n",
    "deletionCount=deletionCount.split()\n",
    "deletionCount=list(map(float,deletionCount))\n",
    "deletionCount=np.array(deletionCount)\n",
    "file.close()\n",
    "\n",
    "# get total parsed base count\n",
    "file=open(\"parselog.txt\",\"r\")\n",
    "line=file.readline()\n",
    "Mlen=float(line)\n",
    "\n",
    "print(\"Ilen:\",Ilen)\n",
    "print(\"Icount:\",Icount)\n",
    "print(\"Dlen:\",Dlen)\n",
    "print(\"Dcount:\",Dcount)\n",
    "print(\"Mlen:\",Mlen)\n",
    "InsertionProb=Ilen/(Icount*Mlen)\n",
    "DeletionProb=Dlen/(Mlen*Dcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log10(baseMatrix)\n",
    "# baseMatrix=10*baseMatrix\n",
    "baseMatrixLog=np.log10(baseMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read list from contigs.txt\n",
    "fasta_file = \"E:\\\\Studies\\\\4-1\\\\CSE 400\\\\drive\\\\outputs\\\\canu\\\\real_SAMN10819805_pacbio_00_canu_v1.9.fasta\"\n",
    "hash_table_contig=HashTable(100)\n",
    "contigFile=open(fasta_file,\"r\")\n",
    "line=contigFile.readline()\n",
    "contig=\"\"\n",
    "contigsCount=0\n",
    "contigName=\"\"\n",
    "contigLengthTotal=0\n",
    "while line:\n",
    "    if line[0]=='>':\n",
    "        if contigsCount==0:\n",
    "            contigName=re.split(\"\\t| \",line)[0][1:].strip()\n",
    "            contigsCount+=1\n",
    "            line=contigFile.readline()\n",
    "\n",
    "        else:\n",
    "            hash_table_contig.set_val(contigName,contig)\n",
    "            contigName=re.split(\"\\t| \",line)[0][1:].strip()\n",
    "            contigsCount+=1\n",
    "            contigLengthTotal+=len(contig)\n",
    "            contig=\"\"\n",
    "            line=contigFile.readline()\n",
    "        continue\n",
    "    line=line.strip()\n",
    "    contig += line\n",
    "    line=contigFile.readline()\n",
    "contigFile.close()\n",
    "hash_table_contig.set_val(contigName,contig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_table = HashTable(50000)\n",
    "posProbCount=0\n",
    "mappedFile=open(\"mappedread.txt\",\"r\")\n",
    "line=mappedFile.readline()\n",
    "while line:\n",
    "    line=line.strip()\n",
    "    line=re.split(\"\\t\",line)\n",
    "    readName=line[0]\n",
    "\n",
    "    flagg=line[1]\n",
    "\n",
    "    strand=(int(flagg)&16)>>4\n",
    "    contigName=line[2]\n",
    "    contigs1D=hash_table_contig.get_val(contigName)\n",
    "    if contigs1D==\"No\":\n",
    "        print(\"No contig found\")\n",
    "        break\n",
    "    position=int(line[3])-1\n",
    "    ciger=line[4]\n",
    "    cigerValues=re.split(\"S|M|I|D|H\",ciger)\n",
    "    cigerPosition=0\n",
    "\n",
    "    rawRead=line[5]\n",
    "    rawRead=re.split(\"\\n\",rawRead)\n",
    "    rawRead=rawRead[0]\n",
    "\n",
    "    baseMatrixI=0\n",
    "    baseMatrixJ=0\n",
    "\n",
    "    readIterator=0\n",
    "    contigPos=position\n",
    "    probability=np.log10(len(rawRead)/contigLengthTotal)\n",
    "    if(strand==1):\n",
    "        rawRead=rawRead[::-1]\n",
    "        rawRead=list(rawRead) \n",
    "        for i in range(len(rawRead)):\n",
    "            if(rawRead[i]=='A'):\n",
    "                rawRead[i]='T'\n",
    "            elif rawRead[i]=='T':\n",
    "                rawRead[i]='A'\n",
    "            elif rawRead[i]=='G':\n",
    "                rawRead[i]= 'C'\n",
    "            elif rawRead[i]=='C':\n",
    "                rawRead[i]= 'G'\n",
    "        rawRead=\"\".join(rawRead)\n",
    "    for i in range(len(cigerValues)-1):\n",
    "        value=int(cigerValues[i])\n",
    "        cigerPosition+=len(cigerValues[i])\n",
    "        cigerOperation=ciger[cigerPosition]\n",
    "        cigerPosition+=1\n",
    "\n",
    "        if cigerOperation==\"M\":\n",
    "            for it in range(value):\n",
    "                \n",
    "                fr=rawRead[readIterator]\n",
    "                to=contigs1D[contigPos]\n",
    "                if fr==\"A\":\n",
    "                    baseMatrixI=0\n",
    "                elif fr==\"T\":\n",
    "                    baseMatrixI=1\n",
    "                elif fr==\"G\":\n",
    "                    baseMatrixI=2\n",
    "                elif fr==\"C\":\n",
    "                    baseMatrixI=3\n",
    "\n",
    "                if to==\"A\":\n",
    "                    baseMatrixJ=0\n",
    "                elif to==\"T\":\n",
    "                    baseMatrixJ=1\n",
    "                elif to==\"G\":\n",
    "                    baseMatrixJ=2\n",
    "                elif to==\"C\":\n",
    "                    baseMatrixJ=3\n",
    "\n",
    "                probability+=baseMatrixLog[baseMatrixI][baseMatrixJ]\n",
    "                readIterator+=1\n",
    "                contigPos+=1\n",
    "        elif cigerOperation==\"I\":\n",
    "            readIterator+=value\n",
    "            probability+=np.log10(insertionCount[value]*InsertionProb)\n",
    "\n",
    "        elif cigerOperation==\"D\":\n",
    "            contigPos+=value\n",
    "            probability+=np.log10(deletionCount[value]*DeletionProb)\n",
    "        elif cigerOperation==\"S\":\n",
    "            readIterator+=value\n",
    "            probability+=np.log10(deletionCount[value]*DeletionProb)\n",
    "        elif cigerOperation==\"H\":\n",
    "            readIterator+=value\n",
    "            probability+=np.log10(deletionCount[value]*DeletionProb)\n",
    "    prev=hash_table.get_val(readName)\n",
    "    hash_table.set_val(readName,prev +'\\t'+ str(probability))\n",
    "    line=mappedFile.readline()\n",
    "mappedFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_table2=HashTable(50000)\n",
    "mappedFile=open(\"mappedread.txt\",\"r\")\n",
    "line=mappedFile.readline()\n",
    "probStr=[]\n",
    "while line:\n",
    "    line=line.strip()\n",
    "    line=re.split(\"\\t\",line)\n",
    "    readName=line[0]\n",
    "    if(hash_table2.get_val(readName)==\"No\"):\n",
    "        hash_table2.set_val(readName,1)\n",
    "        probStr.append(hash_table.get_val(readName).split('\\t'))\n",
    "    line=mappedFile.readline()\n",
    "mappedFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : No\n",
      "1 : -409.60040659080613\n",
      "2 : -217.0169672291557\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(probStr[0])):\n",
    "    print(i , \":\", probStr[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6663\n",
      "['-409.60040659080613', '-217.0169672291557']\n",
      "44597\n",
      "-1375.529479704059\n"
     ]
    }
   ],
   "source": [
    "\n",
    "newArrayWithDuplicates=[]\n",
    "arrayOfSingleProbability=[]\n",
    "for i in range(len(probStr)):\n",
    "    if(len(probStr[i]) > 2):\n",
    "        newArrayWithDuplicates.append(probStr[i][1:])\n",
    "    else:\n",
    "        arrayOfSingleProbability.append(float(probStr[i][1]))\n",
    "print(len(newArrayWithDuplicates))\n",
    "print(newArrayWithDuplicates[0])\n",
    "print(len(arrayOfSingleProbability))\n",
    "print(arrayOfSingleProbability[0])\n",
    "\n",
    "#write newArrayWithDuplicates to file\n",
    "file=open(\"log10multipleProbForSameRead.txt\",\"w\")\n",
    "for i in range(len(newArrayWithDuplicates)):\n",
    "    for j in range(len(newArrayWithDuplicates[i])):\n",
    "        file.write(newArrayWithDuplicates[i][j])\n",
    "        file.write(\"\\t\")\n",
    "    file.write(\"\\n\")\n",
    "file.close()\n",
    "file=open(\"log10singleProb.txt\",\"w\")\n",
    "file.write(str(sum(arrayOfSingleProbability)))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f027b4592910bbddabc03320229ffb3bed0d0840b4364d0114aa85295a38f7d3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
