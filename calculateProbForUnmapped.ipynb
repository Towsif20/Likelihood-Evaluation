{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashTable:\n",
    "\n",
    "\t# Create empty bucket list of given size\n",
    "\tdef __init__(self, size):\n",
    "\t\tself.size = size\n",
    "\t\tself.hash_table = self.create_buckets()\n",
    "\n",
    "\tdef create_buckets(self):\n",
    "\t\treturn [[] for _ in range(self.size)]\n",
    "\n",
    "\t# Insert values into hash map\n",
    "\tdef set_val(self, key, val):\n",
    "\t\t\n",
    "\t\t# Get the index from the key\n",
    "\t\t# using hash function\n",
    "\t\thashed_key = hash(key) % self.size\n",
    "\t\t\n",
    "\t\t# Get the bucket corresponding to index\n",
    "\t\tbucket = self.hash_table[hashed_key]\n",
    "\n",
    "\t\tfound_key = False\n",
    "\t\tfor index, record in enumerate(bucket):\n",
    "\t\t\trecord_key, record_val = record\n",
    "\t\t\t\n",
    "\t\t\t# check if the bucket has same key as\n",
    "\t\t\t# the key to be inserted\n",
    "\t\t\tif record_key == key:\n",
    "\t\t\t\tfound_key = True\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\t# If the bucket has same key as the key to be inserted,\n",
    "\t\t# Update the key value\n",
    "\t\t# Otherwise append the new key-value pair to the bucket\n",
    "\t\tif found_key:\n",
    "\t\t\tbucket[index] = (key, val)\n",
    "\t\telse:\n",
    "\t\t\tbucket.append((key, val))\n",
    "\n",
    "\t# Return searched value with specific key\n",
    "\tdef get_val(self, key):\n",
    "\t\t\n",
    "\t\t# Get the index from the key using\n",
    "\t\t# hash function\n",
    "\t\thashed_key = hash(key) % self.size\n",
    "\t\t\n",
    "\t\t# Get the bucket corresponding to index\n",
    "\t\tbucket = self.hash_table[hashed_key]\n",
    "\n",
    "\t\tfound_key = False\n",
    "\t\tfor index, record in enumerate(bucket):\n",
    "\t\t\trecord_key, record_val = record\n",
    "\t\t\t\n",
    "\t\t\t# check if the bucket has same key as\n",
    "\t\t\t# the key being searched\n",
    "\t\t\tif record_key == key:\n",
    "\t\t\t\tfound_key = True\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\t# If the bucket has same key as the key being searched,\n",
    "\t\t# Return the value found\n",
    "\t\t# Otherwise indicate there was no record found\n",
    "\t\tif found_key:\n",
    "\t\t\treturn record_val\n",
    "\t\telse:\n",
    "\t\t\treturn \"No record found\"\n",
    "\n",
    "\t# Remove a value with specific key\n",
    "\tdef delete_val(self, key):\n",
    "\t\t\n",
    "\t\t# Get the index from the key using\n",
    "\t\t# hash function\n",
    "\t\thashed_key = hash(key) % self.size\n",
    "\t\t\n",
    "\t\t# Get the bucket corresponding to index\n",
    "\t\tbucket = self.hash_table[hashed_key]\n",
    "\n",
    "\t\tfound_key = False\n",
    "\t\tfor index, record in enumerate(bucket):\n",
    "\t\t\trecord_key, record_val = record\n",
    "\t\t\t\n",
    "\t\t\t# check if the bucket has same key as\n",
    "\t\t\t# the key to be deleted\n",
    "\t\t\tif record_key == key:\n",
    "\t\t\t\tfound_key = True\n",
    "\t\t\t\tbreak\n",
    "\t\tif found_key:\n",
    "\t\t\tbucket.pop(index)\n",
    "\t\treturn\n",
    "\n",
    "\t# To print the items of hash map\n",
    "\tdef __str__(self):\n",
    "\t\treturn \"\".join(str(item) for item in self.hash_table)\n",
    "\n",
    "\n",
    "# hash_table = HashTable(50)\n",
    "\n",
    "# # insert some values\n",
    "# hash_table.set_val('gfg@example.com', 'some value')\n",
    "# print(hash_table)\n",
    "# print()\n",
    "\n",
    "# hash_table.set_val('portal@example.com', 'some other value')\n",
    "# print(hash_table)\n",
    "# print()\n",
    "\n",
    "# # search/access a record with key\n",
    "# print(hash_table.get_val('portal@example.com'))\n",
    "# print()\n",
    "\n",
    "# # delete or remove a value\n",
    "# hash_table.delete_val('portal@example.com')\n",
    "# print(hash_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ilen: 34190402.0\n",
      "Icount: 20681987.0\n",
      "Dlen: 152584408.0\n",
      "Dcount: 13434376.0\n",
      "Mlen: 360274608.0\n"
     ]
    }
   ],
   "source": [
    "#read list from file baseMatrix.txt\n",
    "#calculate probability for each element in the list\n",
    "file=open(\"baseMatrix.txt\",\"r\")\n",
    "line=file.readline()\n",
    "baseMatrix=[]\n",
    "while(line):\n",
    "    line=line.strip()\n",
    "    line=line.split()\n",
    "    baseMatrix.append(line)\n",
    "    line=file.readline()\n",
    "file.close()\n",
    "#convert baseMatrix to float\n",
    "baseMatrix=[[float(i) for i in j] for j in baseMatrix]\n",
    "#make baseMatrix a numpy array\n",
    "baseMatrix=np.array(baseMatrix)\n",
    "\n",
    "# get Insertion counts\n",
    "file=open(\"insertion.txt\",\"r\")\n",
    "line=file.readline()\n",
    "line=line.split()\n",
    "Ilen=float(line[0])\n",
    "Icount=float(line[1])\n",
    "line=file.readline()\n",
    "insertionCount=line\n",
    "insertionCount=insertionCount.split()\n",
    "insertionCount=list(map(float,insertionCount))\n",
    "insertionCount=np.array(insertionCount)\n",
    "#replace each 0 to 1\n",
    "insertionCount[insertionCount==0]=1\n",
    "file.close()\n",
    "\n",
    "# get deletion counts\n",
    "file=open(\"deletion.txt\",\"r\")\n",
    "line=file.readline()\n",
    "line=line.split()\n",
    "Dlen=float(line[0])\n",
    "Dcount=float(line[1])\n",
    "line=file.readline()\n",
    "deletionCount=line\n",
    "deletionCount=deletionCount.split()\n",
    "deletionCount=list(map(float,deletionCount))\n",
    "deletionCount=np.array(deletionCount)\n",
    "#replace each 0 to 1\n",
    "deletionCount[deletionCount==0]=1\n",
    "file.close()\n",
    "\n",
    "# get total parsed base count\n",
    "file=open(\"parselog.txt\",\"r\")\n",
    "line=file.readline()\n",
    "Mlen=float(line)\n",
    "\n",
    "print(\"Ilen:\",Ilen)\n",
    "print(\"Icount:\",Icount)\n",
    "print(\"Dlen:\",Dlen)\n",
    "print(\"Dcount:\",Dcount)\n",
    "print(\"Mlen:\",Mlen)\n",
    "InsertionProb=Ilen/(Icount*Mlen)\n",
    "DeletionProb=Dlen/(Mlen*Dcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseMatrixLog=np.log10(baseMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_file = \"E:\\\\Studies\\\\4-1\\\\CSE 400\\\\drive\\\\inputs\\\\real_SAMN10819805_pacbio_00.fastq\"\n",
    "\n",
    "file=open(read_file,'r')\n",
    "line=file.readline()\n",
    "readCountRaw=0\n",
    "readTemplateraw=[]\n",
    "readNameraw=[]\n",
    "while line:\n",
    "    if line[0]=='@':\n",
    "        line=line.strip()\n",
    "        line=re.split(\"@|\\t| \",line)\n",
    "        line=line[1]\n",
    "        readTemplateraw.append(line)\n",
    "        read=file.readline().strip()\n",
    "        readNameraw.append(read)\n",
    "        readCountRaw +=1\n",
    "    line=file.readline()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_table=HashTable(readCountRaw)\n",
    "for i in range(readCountRaw):\n",
    "    hash_table.set_val(readTemplateraw[i],len(readNameraw[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_file = \"E:\\\\Studies\\\\4-1\\\\CSE 400\\\\drive\\\\outputs\\\\canu\\\\real_SAMN10819805_pacbio_00_canu_v1.9.fasta\"\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "hash_table_contig=HashTable(100)\n",
    "contigFile=open(fasta_file,\"r\")\n",
    "line=contigFile.readline()\n",
    "contig=\"\"\n",
    "contigsCount=0\n",
    "contigName=\"\"\n",
    "contigLengthTotal=0\n",
    "while line:\n",
    "    if line[0]=='>':\n",
    "        if contigsCount==0:\n",
    "            contigName=re.split(\"\\t| \",line)[0][1:].strip()\n",
    "            contigsCount+=1\n",
    "            line=contigFile.readline()\n",
    "\n",
    "        else:\n",
    "            hash_table_contig.set_val(contigName,contig)\n",
    "            contigName=re.split(\"\\t| \",line)[0][1:].strip()\n",
    "            contigsCount+=1\n",
    "            contigLengthTotal+=len(contig)\n",
    "            contig=\"\"\n",
    "            line=contigFile.readline()\n",
    "        continue\n",
    "    line=line.strip()\n",
    "    contig += line\n",
    "    line=contigFile.readline()\n",
    "contigFile.close()\n",
    "hash_table_contig.set_val(contigName,contig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalProb=0\n",
    "totalLength=0\n",
    "posProbCount=0\n",
    "mappedFile=open(\"unmappedOut.sam\",\"r\")\n",
    "line=mappedFile.readline()\n",
    "while line:\n",
    "    line=line.strip()\n",
    "    line=re.split(\"\\t\",line)\n",
    "    readName=line[0]\n",
    "\n",
    "    flagg=line[1]\n",
    "\n",
    "    strand=(int(flagg)&16)>>4\n",
    "    contigName=line[2]\n",
    "    contigs1D=hash_table_contig.get_val(contigName)\n",
    "    if contigs1D==\"No record found\":\n",
    "        print(contigName)\n",
    "        print(\"contig not found\")\n",
    "        break\n",
    "    position=int(line[3])-1\n",
    "    ciger=line[4]\n",
    "    cigerValues=re.split(\"S|M|I|D|H\",ciger)\n",
    "    cigerPosition=0\n",
    "\n",
    "    rawRead=line[5]\n",
    "    rawRead=rawRead.strip()\n",
    "    rawReadLength=len(rawRead)\n",
    "\n",
    "    baseMatrixI=0\n",
    "    baseMatrixJ=0\n",
    "\n",
    "    readIterator=0\n",
    "    contigPos=position\n",
    "    probability=np.log10(rawReadLength/contigLengthTotal)\n",
    "    if(strand==1):\n",
    "        rawRead=rawRead[::-1]\n",
    "        rawRead=list(rawRead) \n",
    "        for i in range(len(rawRead)):\n",
    "            if(rawRead[i]=='A'):\n",
    "                rawRead[i]='T'\n",
    "            elif rawRead[i]=='T':\n",
    "                rawRead[i]='A'\n",
    "            elif rawRead[i]=='G':\n",
    "                rawRead[i]= 'C'\n",
    "            elif rawRead[i]=='C':\n",
    "                rawRead[i]= 'G'\n",
    "        rawRead=\"\".join(rawRead)\n",
    "    for i in range(len(cigerValues)-1):\n",
    "        value=int(cigerValues[i])\n",
    "        cigerPosition+=len(cigerValues[i])\n",
    "        cigerOperation=ciger[cigerPosition]\n",
    "        cigerPosition+=1\n",
    "\n",
    "        if cigerOperation==\"M\":\n",
    "            for it in range(value):\n",
    "                \n",
    "                fr=rawRead[readIterator]\n",
    "                to=contigs1D[contigPos]\n",
    "                if fr==\"A\":\n",
    "                    baseMatrixI=0\n",
    "                elif fr==\"T\":\n",
    "                    baseMatrixI=1\n",
    "                elif fr==\"G\":\n",
    "                    baseMatrixI=2\n",
    "                elif fr==\"C\":\n",
    "                    baseMatrixI=3\n",
    "\n",
    "                if to==\"A\":\n",
    "                    baseMatrixJ=0\n",
    "                elif to==\"T\":\n",
    "                    baseMatrixJ=1\n",
    "                elif to==\"G\":\n",
    "                    baseMatrixJ=2\n",
    "                elif to==\"C\":\n",
    "                    baseMatrixJ=3\n",
    "\n",
    "                probability+=baseMatrixLog[baseMatrixI][baseMatrixJ]\n",
    "                readIterator+=1\n",
    "                contigPos+=1\n",
    "        elif cigerOperation==\"I\":\n",
    "            readIterator+=value\n",
    "            probability+=np.log10(insertionCount[value]*InsertionProb)\n",
    "\n",
    "        elif cigerOperation==\"D\":\n",
    "            contigPos+=value\n",
    "            probability+=np.log10(deletionCount[value]*DeletionProb)\n",
    "        elif cigerOperation==\"S\":\n",
    "            readIterator+=value\n",
    "            probability+=np.log10(deletionCount[value]*DeletionProb)\n",
    "        elif cigerOperation==\"H\":\n",
    "            readIterator+=value\n",
    "            probability+=np.log10(deletionCount[value]*DeletionProb)\n",
    "\n",
    "    \n",
    "    probability/=len(rawRead)\n",
    "    probability*=hash_table.get_val(readName)\n",
    "    totalProb+=probability\n",
    "    totalLength+=hash_table.get_val(readName)\n",
    "    line=mappedFile.readline()\n",
    "mappedFile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open(\"unmapped_statistics.txt\",\"r\")\n",
    "line=file.readline()\n",
    "line=line.strip()\n",
    "line=re.split(\"\\t\",line)\n",
    "totalUnmappedLength=int(line[1])\n",
    "perBaseProb=totalProb/totalLength\n",
    "file.close()\n",
    "unmappedProbability=perBaseProb*totalUnmappedLength\n",
    "file=open(\"unmappedLogProbability.txt\",\"w\")\n",
    "file.write(str(unmappedProbability))\n",
    "file.close()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f027b4592910bbddabc03320229ffb3bed0d0840b4364d0114aa85295a38f7d3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
